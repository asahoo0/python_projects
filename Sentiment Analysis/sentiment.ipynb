{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### Improved sentiment analysis classifer ###\n",
        "# Uses k-fold cross validation and Naive Bayes, Decision Tree, and Bernoulli ML models #\n",
        "# Outputs average accuracy of the model #\n",
        "import tarfile\n",
        "import collections\n",
        "import nltk\n",
        "import sys\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import KFold, ShuffleSplit\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk import classify\n",
        "from nltk.classify import SklearnClassifier\n",
        "from nltk import NaiveBayesClassifier, DecisionTreeClassifier\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.metrics.scores import precision, recall\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import os"
      ],
      "metadata": {
        "id": "03OuTlN8C05p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only run this cell once for download if necessary\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FML3Il3_EYpa",
        "outputId": "b2656758-aee5-45d5-e0fa-0ec363ad810b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training/testing data files\n",
        "polaritytar = tarfile.open(\"../Data/review_polarity.tar.gz\", \"r\")\n",
        "polaritytar.extractall('../Data/Polarity_Data')\n",
        "\n",
        "nrctar = tarfile.open(\"NRC-Sentiment-Emotion-Lexicons.tar.gz\", 'r')\n",
        "nrctar.extractall('NRC_Data')"
      ],
      "metadata": {
        "id": "gZqPRUzXC6Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the lines from all the reviews\n",
        "\n",
        "# lines from negative reviews\n",
        "neglines = []\n",
        "for nfilename in os.listdir('../Data/Polarity_Data/txt_sentoken/neg'):\n",
        "    openFile = open(('../Data/Polarity_Data/txt_sentoken/neg/' + nfilename),\"r\")\n",
        "    neglines = openFile.readlines()\n",
        "\n",
        "# lines from positive reviews\n",
        "poslines = []\n",
        "for pfilename in os.listdir('../Data/Polarity_Data/txt_sentoken/pos'):\n",
        "    openFile = open(('../Data/Polarity_Data/txt_sentoken/pos/' + pfilename),\"r\")\n",
        "    poslines = openFile.readlines()\n",
        "    \n",
        "intensity_file = open('../Data/NRC_Data/NRC-Sentiment-Emotion-Lexicons/NRC-Sentiment-Emotion-Lexicons/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt')\n",
        "intensity_lines = intensity_file.readlines()"
      ],
      "metadata": {
        "id": "n_069p-MIIYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "word_emotions = dict()\n",
        "\n",
        "\n",
        "# use the data from affect-intensity file\n",
        "for line in intensity_lines[1:]:\n",
        "    features = line.split()\n",
        "    # features[0]: the word\n",
        "    # features[2]: the primary sentiment (fear, sadness, anger, joy)\n",
        "    if features[2] == '1':\n",
        "        word_emotion = (lemmatizer.lemmatize(features[0]), features[1])\n",
        "        word_emotions.update({word_emotion})"
      ],
      "metadata": {
        "id": "NpHtA3S5IYYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCYIZNHdstkx"
      },
      "outputs": [],
      "source": [
        "# tokens for positive reviews\n",
        "poslines_tokens = []\n",
        "for line in poslines:\n",
        "    l = []\n",
        "    for word in line.split():\n",
        "        l.append(word)\n",
        "    poslines_tokens.append(l)\n",
        "# tokens for negative reviews\n",
        "neglines_tokens = []\n",
        "for line in neglines:\n",
        "    l = []\n",
        "    for word in line.split():\n",
        "        l.append(word)\n",
        "    neglines_tokens.append(l)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to remove non-alphanumeric characters and lowercase each token\n",
        "def clean_tokens(tokens):\n",
        "\n",
        "    cleaned_tokens = []\n",
        "    for token in tokens:\n",
        "        # removing stop words decreased performance significantly\n",
        "        if len(token) != 0 and token not in string.punctuation: # and token.lower() not in stopwords.words('english'):\n",
        "            cleaned_tokens.append(lemmatizer.lemmatize(token.lower()))\n",
        "\n",
        "    # return pos_tag(cleaned_tokens) - not useful so didn't end up using\n",
        "    return cleaned_tokens"
      ],
      "metadata": {
        "id": "DBblsS6-HCO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up the tokens list\n",
        "positive_cleaned_tokens = []\n",
        "negative_cleaned_tokens = []\n",
        "\n",
        "for tokens in poslines_tokens:\n",
        "    positive_cleaned_tokens.append(clean_tokens(tokens))\n",
        "\n",
        "for tokens in neglines_tokens:\n",
        "    negative_cleaned_tokens.append(clean_tokens(tokens))"
      ],
      "metadata": {
        "id": "8xNpsZcXDN75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to create the model from the tokens list\n",
        "def create_model(cleaned_tokens_list):\n",
        "    for tokens in cleaned_tokens_list:\n",
        "        yield dict([token, True] for token in tokens)\n",
        "positive_tokens_for_model = create_model(positive_cleaned_tokens)\n",
        "negative_tokens_for_model = create_model(negative_cleaned_tokens)\n",
        "# categorize the tokens in each review\n",
        "positive_dataset = [(t,\"Positive\") for t in positive_tokens_for_model]\n",
        "negative_dataset = [(t,\"Negative\") for t in negative_tokens_for_model]\n",
        "positive_emotions = ['positive', 'anticipation', 'joy', 'surprise', 'trust']\n",
        "negative_emotions = ['anger', 'disgust', 'fear', 'negative', 'sadness']\n",
        "# here we remove words from \"conflicting\" sentiments from the reviews\n",
        "# i.e. if there is a word in a review marked as positive that has a \"sadness\" label, that word will be removed"
      ],
      "metadata": {
        "id": "7Ndw5UgyGoC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove negative words from the set of positive reviews\n",
        "pos_to_remove = list()\n",
        "for (review, sentiment) in positive_dataset:\n",
        "    for word in review:\n",
        "        if word in word_emotions and word_emotions[word] in negative_emotions:\n",
        "            pos_to_remove.append(word)\n",
        "\n",
        "for (review, sentiment) in positive_dataset:\n",
        "    for neg_word in pos_to_remove:\n",
        "        if neg_word in review.keys():\n",
        "            review.pop(neg_word)"
      ],
      "metadata": {
        "id": "khyU_-mGDJ2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove positive words from the set of negative reviews\n",
        "neg_to_remove = list()\n",
        "for (review, sentiment) in negative_dataset:\n",
        "  for word in review:\n",
        "    if word in word_emotions and word_emotions[word] in positive_emotions:\n",
        "      neg_to_remove.append(word)\n",
        "\n",
        "for (review, sentiment) in negative_dataset:\n",
        "  for pos_word in neg_to_remove:\n",
        "    if pos_word in review.keys():\n",
        "      review.pop(pos_word)\n",
        "dataset = positive_dataset + negative_dataset"
      ],
      "metadata": {
        "id": "xtAHT_4HGdA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_dataset = np.array(dataset)\n",
        "# use k-fold cross validation with k = 9 to train and test\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=35)\n",
        "nb_mean_accuracy, dt_mean_accuracy, bern_mean_accuracy = list(), list(), list()\n",
        "nb_mean_precision, dt_mean_precision, bern_mean_precision = list(), list(), list()\n",
        "\n",
        "for train, test in kfold.split(np_dataset):\n",
        "    # naive bayes classifier\n",
        "    nb_classifier = NaiveBayesClassifier.train(np_dataset[train])\n",
        "    nb_mean_accuracy.append(classify.accuracy(nb_classifier, np_dataset[test]))\n",
        "\n",
        "    # decitions tree classifier\n",
        "    dt_classifier = DecisionTreeClassifier.train(np_dataset[train])\n",
        "    dt_mean_accuracy.append(classify.accuracy(dt_classifier, np_dataset[test]))\n",
        "\n",
        "    # bernoulli classifier\n",
        "    bern_classifier = SklearnClassifier(BernoulliNB()).train(np_dataset[train])\n",
        "    bern_mean_accuracy.append(classify.accuracy(bern_classifier, np_dataset[test]))\n",
        "    \n",
        "    refsets = collections.defaultdict(set)\n",
        "    testsets = collections.defaultdict(set)\n",
        "\n",
        "    classifiers = [nb_classifier, dt_classifier, bern_classifier]\n",
        "\n",
        "    for classifier in classifiers:\n",
        "        for i, (feats, label) in enumerate(np_dataset[test]):\n",
        "            refsets[label].add(i)\n",
        "            observed = classifier.classify(feats)\n",
        "            testsets[observed].add(i)   \n",
        "\n",
        "        if classifier == nb_classifier:\n",
        "            nb_mean_precision.append(precision(refsets['Positive'], testsets['Positive']))\n",
        "            nb_mean_precision.append(precision(refsets['Negative'], testsets['Negative']))\n",
        "            nb_mean_precision = list(filter(None, nb_mean_precision))\n",
        "\n",
        "        elif classifier == dt_classifier:\n",
        "            dt_mean_precision.append(precision(refsets['Positive'], testsets['Positive']))\n",
        "            dt_mean_precision.append(precision(refsets['Negative'], testsets['Negative']))\n",
        "            dt_mean_precision = list(filter(None, dt_mean_precision))\n",
        "\n",
        "        elif classifier == bern_classifier:\n",
        "            bern_mean_precision.append(precision(refsets['Positive'], testsets['Positive']))\n",
        "            bern_mean_precision.append(precision(refsets['Negative'], testsets['Negative']))\n",
        "            bern_mean_precision = list(filter(None, bern_mean_precision))"
      ],
      "metadata": {
        "id": "3zEwfSXRCqXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the mean accuracy across all the folds for each classifier\n",
        "print(\"Naive Bayes accuracy:\", np.mean(nb_mean_accuracy))\n",
        "print(\"Naive Bayes precision:\", np.mean(nb_mean_precision))\n",
        "print('\\n')\n",
        "print(\"Decision Tree accuracy:\", np.mean(dt_mean_accuracy))\n",
        "print(\"Decision Tree precision:\", np.mean(dt_mean_precision))\n",
        "print('\\n')\n",
        "print(\"Bernoulli accuracy:\", np.mean(bern_mean_accuracy))\n",
        "print(\"Bernoulli precision:\", np.mean(bern_mean_precision))"
      ],
      "metadata": {
        "id": "x-Uf6it9CnMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b309c5-2812-4bf7-f92f-b7d5cc50b5a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy: 0.8066666666666666\n",
            "Naive Bayes precision: 0.8888888888888888\n",
            "\n",
            "\n",
            "Decision Tree accuracy: 0.8066666666666666\n",
            "Decision Tree precision: 0.8157407407407408\n",
            "\n",
            "\n",
            "Bernoulli accuracy: 0.7166666666666666\n",
            "Bernoulli precision: 0.7222222222222222\n"
          ]
        }
      ]
    }
  ]
}